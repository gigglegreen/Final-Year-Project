{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data97=pd.read_csv('data/97.csv')\n",
    "data105=pd.read_csv('data/105.csv')\n",
    "data118=pd.read_csv('data/118.csv')\n",
    "data130=pd.read_csv('data/130.csv')\n",
    "data169=pd.read_csv('data/169.csv')\n",
    "data185=pd.read_csv('data/185.csv')\n",
    "data197=pd.read_csv('data/197.csv')\n",
    "data209=pd.read_csv('data/209.csv')\n",
    "data222=pd.read_csv('data/222.csv')\n",
    "data234=pd.read_csv('data/234.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243938, 4)\n",
      "Unnamed: 0      False\n",
      "X097_DE_time    False\n",
      "X097_FE_time    False\n",
      "X097RPM          True\n",
      "dtype: bool\n",
      "(121265, 5)\n",
      "Unnamed: 0      False\n",
      "X105_DE_time    False\n",
      "X105_FE_time    False\n",
      "X105_BA_time    False\n",
      "X105RPM          True\n",
      "dtype: bool\n",
      "(122571, 5)\n",
      "Unnamed: 0      False\n",
      "X118_DE_time    False\n",
      "X118_FE_time    False\n",
      "X118_BA_time    False\n",
      "X118RPM          True\n",
      "dtype: bool\n",
      "(121991, 5)\n",
      "Unnamed: 0      False\n",
      "X130_DE_time    False\n",
      "X130_FE_time    False\n",
      "X130_BA_time    False\n",
      "X130RPM          True\n",
      "dtype: bool\n",
      "(121846, 5)\n",
      "Unnamed: 0      False\n",
      "X169_DE_time    False\n",
      "X169_FE_time    False\n",
      "X169_BA_time    False\n",
      "X169RPM          True\n",
      "dtype: bool\n",
      "(121846, 5)\n",
      "Unnamed: 0      False\n",
      "X185_DE_time    False\n",
      "X185_FE_time    False\n",
      "X185_BA_time    False\n",
      "X185RPM          True\n",
      "dtype: bool\n",
      "(121846, 5)\n",
      "Unnamed: 0      False\n",
      "X197_DE_time    False\n",
      "X197_FE_time    False\n",
      "X197_BA_time    False\n",
      "X197RPM          True\n",
      "dtype: bool\n",
      "(122136, 5)\n",
      "Unnamed: 0      False\n",
      "X209_DE_time    False\n",
      "X209_FE_time    False\n",
      "X209_BA_time    False\n",
      "X209RPM          True\n",
      "dtype: bool\n",
      "(121991, 5)\n",
      "Unnamed: 0      False\n",
      "X222_DE_time    False\n",
      "X222_FE_time    False\n",
      "X222_BA_time    False\n",
      "X222RPM          True\n",
      "dtype: bool\n",
      "(122426, 5)\n",
      "Unnamed: 0      False\n",
      "X234_DE_time    False\n",
      "X234_FE_time    False\n",
      "X234_BA_time    False\n",
      "X234RPM          True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for i in (data97,data105,data118,data130,data169,data185,data197,data209,data222,data234):\n",
    "    print(i.shape)\n",
    "    print(i.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除多余的列，一个疑问，关于加速度，为什么normal数据没有这个feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data97=data97.drop(['X097RPM','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data105=data105.drop(['X105RPM','Unnamed: 0', 'X105_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data118=data118.drop(['X118RPM','Unnamed: 0', 'X118_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data130=data130.drop(['X130RPM','Unnamed: 0', 'X130_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data169=data169.drop(['X169RPM','Unnamed: 0', 'X169_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data185=data185.drop(['X185RPM','Unnamed: 0', 'X185_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data197=data197.drop(['X197RPM','Unnamed: 0', 'X197_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data209=data209.drop(['X209RPM','Unnamed: 0', 'X209_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data222=data222.drop(['X222RPM','Unnamed: 0', 'X222_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data234=data234.drop(['X234RPM','Unnamed: 0', 'X234_BA_time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X097_DE_time</th>\n",
       "      <th>X097_FE_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.053197</td>\n",
       "      <td>0.145667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088662</td>\n",
       "      <td>0.097796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099718</td>\n",
       "      <td>0.054856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058621</td>\n",
       "      <td>0.036982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.004590</td>\n",
       "      <td>0.054445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X097_DE_time  X097_FE_time\n",
       "0      0.053197      0.145667\n",
       "1      0.088662      0.097796\n",
       "2      0.099718      0.054856\n",
       "3      0.058621      0.036982\n",
       "4     -0.004590      0.054445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data97.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X105_DE_time</th>\n",
       "      <th>X105_FE_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.083004</td>\n",
       "      <td>-0.402075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.195734</td>\n",
       "      <td>-0.004725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233419</td>\n",
       "      <td>-0.106631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103958</td>\n",
       "      <td>-0.074169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.181115</td>\n",
       "      <td>0.208947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X105_DE_time  X105_FE_time\n",
       "0     -0.083004     -0.402075\n",
       "1     -0.195734     -0.004725\n",
       "2      0.233419     -0.106631\n",
       "3      0.103958     -0.074169\n",
       "4     -0.181115      0.208947"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data105.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243938, 2)\n",
      "X097_DE_time    False\n",
      "X097_FE_time    False\n",
      "dtype: bool\n",
      "(121265, 2)\n",
      "X105_DE_time    False\n",
      "X105_FE_time    False\n",
      "dtype: bool\n",
      "(122571, 2)\n",
      "X118_DE_time    False\n",
      "X118_FE_time    False\n",
      "dtype: bool\n",
      "(121991, 2)\n",
      "X130_DE_time    False\n",
      "X130_FE_time    False\n",
      "dtype: bool\n",
      "(121846, 2)\n",
      "X169_DE_time    False\n",
      "X169_FE_time    False\n",
      "dtype: bool\n",
      "(121846, 2)\n",
      "X185_DE_time    False\n",
      "X185_FE_time    False\n",
      "dtype: bool\n",
      "(121846, 2)\n",
      "X197_DE_time    False\n",
      "X197_FE_time    False\n",
      "dtype: bool\n",
      "(122136, 2)\n",
      "X209_DE_time    False\n",
      "X209_FE_time    False\n",
      "dtype: bool\n",
      "(121991, 2)\n",
      "X222_DE_time    False\n",
      "X222_FE_time    False\n",
      "dtype: bool\n",
      "(122426, 2)\n",
      "X234_DE_time    False\n",
      "X234_FE_time    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "for i in (data97,data105,data118,data130,data169,data185,data197,data209,data222,data234):\n",
    "    print(i.shape)\n",
    "    print(i.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# target = np.zeros((1, 10))\n",
    "# target[0][9] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate([target for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = []\n",
    "# for i in range(10):\n",
    "#     a.append(target)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data97 = []\n",
    "# test_data97 = []\n",
    "# n_step = 400    #时序数据的长度\n",
    "# gap =400 #产生时序数据样本的间隔，每隔400个取400个作为时序数据\n",
    "# n = data97.shape[0] // gap #生成时序样本的个数\n",
    "# for i in range(n-1):\n",
    "#     train_data97.append(data97.values[i * gap :(i + 1) * gap])\n",
    "#     #print(len(train_data))\n",
    "# train_data97 = np.array(train_data97)\n",
    "# print(train_data97.shape)\n",
    "# # print(len(train_data97))\n",
    "# train_data97[[0, 3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(data, n_step, gap, sample_number, test_ratio, label):\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "    target = np.zeros((1, 10))\n",
    "    target[0][label] = 1\n",
    "    n = data.shape[0] // gap #生成时序样本的个数\n",
    "    for i in range(n-1):\n",
    "        all_data.append(data.values[i * gap :(i + 1) * gap])\n",
    "    all_data = np.array(all_data)\n",
    "    idx = random.sample(range(all_data.shape[0]), sample_number)#返回了索引list\n",
    "    test_number = int(sample_number * test_ratio)\n",
    "    test_data = all_data[idx[:test_number]]#取test_number个样本作为测试集\n",
    "    train_data = all_data[idx[test_number:]]\n",
    "    train_label = np.concatenate([target for i in range(train_data.shape[0])])\n",
    "    test_label = np.concatenate([target for i in range(test_data.shape[0])])\n",
    "#     print('Train shape: {}'.format(train_data.shape))\n",
    "#     print('Test shape: {}'.format(test_data.shape))\n",
    "    return train_data, test_data, train_label, test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = random.sample(range(100), 10)\n",
    "# print(a)\n",
    "# print(a[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "test_sets = []\n",
    "train_label = []\n",
    "test_label = []\n",
    "data_list = [data97, data105, data118, data130, data169, data185, data197, data209, data222, data234]\n",
    "\n",
    "n_step = 400\n",
    "gap = 400\n",
    "sample_number = 300\n",
    "test_ratio = 0.1\n",
    "\n",
    "\n",
    "\n",
    "for i, data in enumerate(data_list):\n",
    "    a, b, c, d = processing(\n",
    "        data, \n",
    "        n_step = n_step, \n",
    "        gap = gap, \n",
    "        sample_number = sample_number, \n",
    "        test_ratio = test_ratio,\n",
    "        label = i\n",
    "    )\n",
    "    train_sets.append(a)\n",
    "    test_sets.append(b)\n",
    "    train_label.append(c)\n",
    "    test_label.append(d)\n",
    "train_sets = np.concatenate(train_sets)\n",
    "test_sets = np.concatenate(test_sets)\n",
    "train_label = np.concatenate(train_label)\n",
    "test_label = np.concatenate(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state =np.random.get_state()\n",
    "np.random.shuffle(train_sets)\n",
    "np.random.set_state(state)\n",
    "np.random.shuffle(train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 400, 2)\n",
      "(300, 400, 2)\n",
      "(2700, 10)\n",
      "(300, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_sets.shape)\n",
    "print(test_sets.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create and fit the LSTM network\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(32, \n",
    "#                return_sequences=True,\n",
    "#                input_shape=(400, 2),\n",
    "#                activation='relu')\n",
    "#          )\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(LSTM(16, return_sequences=True, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(units=10))\n",
    "# model.add(Activation('softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(32, return_sequences=True, input_shape=(400, 2))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 400, 32)           3360      \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 16)                2352      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 5,882\n",
      "Trainable params: 5,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    GRU(32, input_dim = 2, input_length = 400, return_sequences = True),\n",
    "    GRU(16, return_sequences = False),\n",
    "    # Dropout(0.5),\n",
    "    Dense(10),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "Adam_op = Adam(lr=0.001, decay=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam_op, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 2.3014 - acc: 0.0856 - val_loss: 2.2982 - val_acc: 0.1200\n",
      "Epoch 2/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 2.2944 - acc: 0.1567 - val_loss: 2.2861 - val_acc: 0.1833\n",
      "Epoch 3/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 2.2405 - acc: 0.1774 - val_loss: 1.9752 - val_acc: 0.2000\n",
      "Epoch 4/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.8596 - acc: 0.2011 - val_loss: 1.8188 - val_acc: 0.2100\n",
      "Epoch 5/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.7800 - acc: 0.2070 - val_loss: 1.7828 - val_acc: 0.2233\n",
      "Epoch 6/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.7568 - acc: 0.2059 - val_loss: 1.7690 - val_acc: 0.2900\n",
      "Epoch 7/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.7526 - acc: 0.2548 - val_loss: 1.7773 - val_acc: 0.2433\n",
      "Epoch 8/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.7540 - acc: 0.2819 - val_loss: 1.7822 - val_acc: 0.3133\n",
      "Epoch 9/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.7620 - acc: 0.2674 - val_loss: 1.7767 - val_acc: 0.2600\n",
      "Epoch 10/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.7192 - acc: 0.2900 - val_loss: 1.7190 - val_acc: 0.3633\n",
      "Epoch 11/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.6811 - acc: 0.3530 - val_loss: 1.7142 - val_acc: 0.3767\n",
      "Epoch 12/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.8772 - acc: 0.2996 - val_loss: 1.9069 - val_acc: 0.2867\n",
      "Epoch 13/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.7242 - acc: 0.3207 - val_loss: 1.6636 - val_acc: 0.3833\n",
      "Epoch 14/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.6213 - acc: 0.3522 - val_loss: 1.6432 - val_acc: 0.3600\n",
      "Epoch 15/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.6000 - acc: 0.3674 - val_loss: 1.6049 - val_acc: 0.3767\n",
      "Epoch 16/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.5653 - acc: 0.4104 - val_loss: 1.5842 - val_acc: 0.4000\n",
      "Epoch 17/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.5508 - acc: 0.4281 - val_loss: 1.5805 - val_acc: 0.3767\n",
      "Epoch 18/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.5239 - acc: 0.4404 - val_loss: 1.5178 - val_acc: 0.5000\n",
      "Epoch 19/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.4440 - acc: 0.4644 - val_loss: 1.4284 - val_acc: 0.4533\n",
      "Epoch 20/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.3623 - acc: 0.4537 - val_loss: 1.3784 - val_acc: 0.4433\n",
      "Epoch 21/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.3898 - acc: 0.4481 - val_loss: 1.4333 - val_acc: 0.4233\n",
      "Epoch 22/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.4202 - acc: 0.4426 - val_loss: 1.4167 - val_acc: 0.4400\n",
      "Epoch 23/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.4053 - acc: 0.4122 - val_loss: 1.4168 - val_acc: 0.4067\n",
      "Epoch 24/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.3499 - acc: 0.4393 - val_loss: 1.3585 - val_acc: 0.4600\n",
      "Epoch 25/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.3040 - acc: 0.4622 - val_loss: 1.3283 - val_acc: 0.4667\n",
      "Epoch 26/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.2750 - acc: 0.4633 - val_loss: 1.3645 - val_acc: 0.4267\n",
      "Epoch 27/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3592 - acc: 0.4315 - val_loss: 1.4860 - val_acc: 0.3867\n",
      "Epoch 28/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.4137 - acc: 0.3948 - val_loss: 1.3639 - val_acc: 0.4700\n",
      "Epoch 29/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2709 - acc: 0.4856 - val_loss: 1.2866 - val_acc: 0.4833\n",
      "Epoch 30/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2663 - acc: 0.4722 - val_loss: 1.3258 - val_acc: 0.4900\n",
      "Epoch 31/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.2552 - acc: 0.4915 - val_loss: 1.3285 - val_acc: 0.4533\n",
      "Epoch 32/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2668 - acc: 0.4893 - val_loss: 1.3057 - val_acc: 0.4767\n",
      "Epoch 33/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2681 - acc: 0.4670 - val_loss: 1.2739 - val_acc: 0.5033\n",
      "Epoch 34/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2189 - acc: 0.4948 - val_loss: 1.2365 - val_acc: 0.5300\n",
      "Epoch 35/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2035 - acc: 0.5167 - val_loss: 1.2600 - val_acc: 0.5333\n",
      "Epoch 36/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2005 - acc: 0.5256 - val_loss: 1.2423 - val_acc: 0.5500\n",
      "Epoch 37/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.2632 - acc: 0.5078 - val_loss: 1.3378 - val_acc: 0.5533\n",
      "Epoch 38/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.2434 - acc: 0.5085 - val_loss: 1.2348 - val_acc: 0.4867\n",
      "Epoch 39/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.2295 - acc: 0.4752 - val_loss: 1.3050 - val_acc: 0.4433\n",
      "Epoch 40/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2918 - acc: 0.4552 - val_loss: 1.3580 - val_acc: 0.4533\n",
      "Epoch 41/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2644 - acc: 0.4852 - val_loss: 1.2633 - val_acc: 0.4867\n",
      "Epoch 42/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.4965 - acc: 0.4041 - val_loss: 1.8689 - val_acc: 0.3067\n",
      "Epoch 43/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.6683 - acc: 0.3200 - val_loss: 1.5472 - val_acc: 0.3200\n",
      "Epoch 44/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.4779 - acc: 0.3715 - val_loss: 1.5078 - val_acc: 0.3467\n",
      "Epoch 45/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.4114 - acc: 0.3981 - val_loss: 1.4562 - val_acc: 0.4133\n",
      "Epoch 46/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3900 - acc: 0.4148 - val_loss: 1.4292 - val_acc: 0.4400\n",
      "Epoch 47/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3707 - acc: 0.4296 - val_loss: 1.4174 - val_acc: 0.4200\n",
      "Epoch 48/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3717 - acc: 0.4148 - val_loss: 1.3872 - val_acc: 0.4300\n",
      "Epoch 49/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.3515 - acc: 0.4181 - val_loss: 1.3735 - val_acc: 0.4400\n",
      "Epoch 50/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3298 - acc: 0.4533 - val_loss: 1.3408 - val_acc: 0.4833\n",
      "Epoch 51/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3049 - acc: 0.4830 - val_loss: 1.3014 - val_acc: 0.5400\n",
      "Epoch 52/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2935 - acc: 0.5037 - val_loss: 1.3760 - val_acc: 0.4867\n",
      "Epoch 53/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.7664 - acc: 0.4033 - val_loss: 1.6939 - val_acc: 0.3833\n",
      "Epoch 54/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.6043 - acc: 0.4181 - val_loss: 1.5179 - val_acc: 0.4300\n",
      "Epoch 55/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.4586 - acc: 0.4437 - val_loss: 1.4176 - val_acc: 0.4667\n",
      "Epoch 56/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3911 - acc: 0.4585 - val_loss: 1.3744 - val_acc: 0.4600\n",
      "Epoch 57/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.3574 - acc: 0.4685 - val_loss: 1.3397 - val_acc: 0.4700\n",
      "Epoch 58/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.3294 - acc: 0.4781 - val_loss: 1.3170 - val_acc: 0.4867\n",
      "Epoch 59/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3069 - acc: 0.4919 - val_loss: 1.3608 - val_acc: 0.4400\n",
      "Epoch 60/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.3257 - acc: 0.4922 - val_loss: 1.3211 - val_acc: 0.4933\n",
      "Epoch 61/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2805 - acc: 0.4885 - val_loss: 1.2439 - val_acc: 0.4900\n",
      "Epoch 62/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.2425 - acc: 0.5093 - val_loss: 1.2550 - val_acc: 0.5067\n",
      "Epoch 63/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.2301 - acc: 0.5052 - val_loss: 1.2197 - val_acc: 0.5467\n",
      "Epoch 64/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.2046 - acc: 0.5148 - val_loss: 1.2076 - val_acc: 0.5233\n",
      "Epoch 65/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.2519 - acc: 0.4919 - val_loss: 1.3113 - val_acc: 0.4367\n",
      "Epoch 66/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.2458 - acc: 0.5033 - val_loss: 1.1915 - val_acc: 0.5133\n",
      "Epoch 67/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.1662 - acc: 0.5256 - val_loss: 1.1570 - val_acc: 0.5500\n",
      "Epoch 68/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.1386 - acc: 0.5404 - val_loss: 1.1492 - val_acc: 0.5433\n",
      "Epoch 69/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.1163 - acc: 0.5452 - val_loss: 1.1293 - val_acc: 0.5467\n",
      "Epoch 70/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.0908 - acc: 0.5552 - val_loss: 1.1206 - val_acc: 0.5533\n",
      "Epoch 71/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.0916 - acc: 0.5493 - val_loss: 1.0953 - val_acc: 0.5533\n",
      "Epoch 72/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.0692 - acc: 0.5759 - val_loss: 1.0837 - val_acc: 0.5733\n",
      "Epoch 73/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0569 - acc: 0.5678 - val_loss: 1.0974 - val_acc: 0.5533\n",
      "Epoch 74/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 1.0854 - acc: 0.5533 - val_loss: 1.1190 - val_acc: 0.5433\n",
      "Epoch 75/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.0535 - acc: 0.5726 - val_loss: 1.0601 - val_acc: 0.5667\n",
      "Epoch 76/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0252 - acc: 0.5904 - val_loss: 1.0430 - val_acc: 0.5867\n",
      "Epoch 77/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0155 - acc: 0.5889 - val_loss: 1.0129 - val_acc: 0.5800\n",
      "Epoch 78/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0122 - acc: 0.5981 - val_loss: 1.0302 - val_acc: 0.6000\n",
      "Epoch 79/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9950 - acc: 0.6196 - val_loss: 0.9881 - val_acc: 0.6000\n",
      "Epoch 80/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9852 - acc: 0.6119 - val_loss: 0.9698 - val_acc: 0.6233\n",
      "Epoch 81/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9656 - acc: 0.6419 - val_loss: 0.9559 - val_acc: 0.6433\n",
      "Epoch 82/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9628 - acc: 0.6374 - val_loss: 0.9825 - val_acc: 0.6000\n",
      "Epoch 83/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.9327 - acc: 0.6533 - val_loss: 0.9280 - val_acc: 0.6467\n",
      "Epoch 84/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.9162 - acc: 0.6622 - val_loss: 0.9622 - val_acc: 0.6633\n",
      "Epoch 85/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9136 - acc: 0.6615 - val_loss: 0.9161 - val_acc: 0.6700\n",
      "Epoch 86/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9119 - acc: 0.6604 - val_loss: 0.9502 - val_acc: 0.6767\n",
      "Epoch 87/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8995 - acc: 0.6689 - val_loss: 0.9377 - val_acc: 0.6533\n",
      "Epoch 88/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.9277 - acc: 0.6541 - val_loss: 0.9461 - val_acc: 0.6800\n",
      "Epoch 89/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8803 - acc: 0.6707 - val_loss: 0.9504 - val_acc: 0.6433\n",
      "Epoch 90/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8715 - acc: 0.6756 - val_loss: 0.8576 - val_acc: 0.7033\n",
      "Epoch 91/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8440 - acc: 0.6941 - val_loss: 0.8394 - val_acc: 0.7100\n",
      "Epoch 92/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.8327 - acc: 0.6981 - val_loss: 0.8296 - val_acc: 0.7000\n",
      "Epoch 93/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8066 - acc: 0.7178 - val_loss: 0.8118 - val_acc: 0.7133\n",
      "Epoch 94/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7880 - acc: 0.7207 - val_loss: 0.8237 - val_acc: 0.7100\n",
      "Epoch 95/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7853 - acc: 0.7215 - val_loss: 0.7969 - val_acc: 0.7200\n",
      "Epoch 96/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7780 - acc: 0.7204 - val_loss: 0.7669 - val_acc: 0.7367\n",
      "Epoch 97/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8433 - acc: 0.6937 - val_loss: 0.8024 - val_acc: 0.7000\n",
      "Epoch 98/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8174 - acc: 0.7048 - val_loss: 0.7747 - val_acc: 0.7400\n",
      "Epoch 99/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7572 - acc: 0.7352 - val_loss: 0.7842 - val_acc: 0.7133\n",
      "Epoch 100/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7465 - acc: 0.7433 - val_loss: 0.7436 - val_acc: 0.7367\n",
      "Epoch 101/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7334 - acc: 0.7444 - val_loss: 0.7282 - val_acc: 0.7500\n",
      "Epoch 102/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7202 - acc: 0.7456 - val_loss: 0.7428 - val_acc: 0.7333\n",
      "Epoch 103/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7344 - acc: 0.7448 - val_loss: 0.7266 - val_acc: 0.7333\n",
      "Epoch 104/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7072 - acc: 0.7544 - val_loss: 0.7098 - val_acc: 0.7467\n",
      "Epoch 105/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7014 - acc: 0.7470 - val_loss: 0.6960 - val_acc: 0.7533\n",
      "Epoch 106/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6996 - acc: 0.7648 - val_loss: 0.6929 - val_acc: 0.7700\n",
      "Epoch 107/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6941 - acc: 0.7611 - val_loss: 0.7056 - val_acc: 0.7400\n",
      "Epoch 108/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6751 - acc: 0.7600 - val_loss: 0.6757 - val_acc: 0.7533\n",
      "Epoch 109/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6822 - acc: 0.7600 - val_loss: 0.6834 - val_acc: 0.7367\n",
      "Epoch 110/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.6651 - acc: 0.7670 - val_loss: 0.6565 - val_acc: 0.7733\n",
      "Epoch 111/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6647 - acc: 0.7693 - val_loss: 0.6694 - val_acc: 0.7667\n",
      "Epoch 112/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7274 - acc: 0.7293 - val_loss: 0.7204 - val_acc: 0.7067\n",
      "Epoch 113/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6676 - acc: 0.7633 - val_loss: 0.6471 - val_acc: 0.7767\n",
      "Epoch 114/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.9873 - acc: 0.6259 - val_loss: 0.9942 - val_acc: 0.6167\n",
      "Epoch 115/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7462 - acc: 0.7281 - val_loss: 0.6839 - val_acc: 0.7400\n",
      "Epoch 116/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6714 - acc: 0.7652 - val_loss: 0.6674 - val_acc: 0.7600\n",
      "Epoch 117/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6670 - acc: 0.7800 - val_loss: 0.6467 - val_acc: 0.7600\n",
      "Epoch 118/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6424 - acc: 0.7770 - val_loss: 0.6595 - val_acc: 0.7633\n",
      "Epoch 119/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6364 - acc: 0.7807 - val_loss: 0.6351 - val_acc: 0.7800\n",
      "Epoch 120/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6371 - acc: 0.7793 - val_loss: 0.6225 - val_acc: 0.7900\n",
      "Epoch 121/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6259 - acc: 0.7778 - val_loss: 0.6420 - val_acc: 0.7833\n",
      "Epoch 122/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6115 - acc: 0.7804 - val_loss: 0.6234 - val_acc: 0.7900\n",
      "Epoch 123/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6015 - acc: 0.7911 - val_loss: 0.6171 - val_acc: 0.7767\n",
      "Epoch 124/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6122 - acc: 0.7807 - val_loss: 0.6490 - val_acc: 0.7767\n",
      "Epoch 125/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6636 - acc: 0.7604 - val_loss: 0.6235 - val_acc: 0.7933\n",
      "Epoch 126/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5983 - acc: 0.7915 - val_loss: 0.5990 - val_acc: 0.7933\n",
      "Epoch 127/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.5874 - acc: 0.7944 - val_loss: 0.6049 - val_acc: 0.8067\n",
      "Epoch 128/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5860 - acc: 0.7963 - val_loss: 0.6873 - val_acc: 0.7567\n",
      "Epoch 129/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.8294 - acc: 0.6956 - val_loss: 0.8538 - val_acc: 0.7367\n",
      "Epoch 130/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.7132 - acc: 0.7489 - val_loss: 0.7463 - val_acc: 0.7600\n",
      "Epoch 131/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0700 - acc: 0.6322 - val_loss: 1.0850 - val_acc: 0.5533\n",
      "Epoch 132/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 1.0228 - acc: 0.6733 - val_loss: 1.1637 - val_acc: 0.6233\n",
      "Epoch 133/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 1.0959 - acc: 0.6559 - val_loss: 1.1083 - val_acc: 0.6033\n",
      "Epoch 134/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.9233 - acc: 0.6726 - val_loss: 0.9598 - val_acc: 0.6333\n",
      "Epoch 135/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.8987 - acc: 0.6333 - val_loss: 0.7946 - val_acc: 0.7000\n",
      "Epoch 136/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.7113 - acc: 0.7585 - val_loss: 0.6222 - val_acc: 0.7900\n",
      "Epoch 137/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6376 - acc: 0.7774 - val_loss: 0.6744 - val_acc: 0.7733\n",
      "Epoch 138/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.6482 - acc: 0.7763 - val_loss: 0.6281 - val_acc: 0.7700\n",
      "Epoch 139/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6143 - acc: 0.7981 - val_loss: 0.6393 - val_acc: 0.7700\n",
      "Epoch 140/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6116 - acc: 0.7967 - val_loss: 0.6934 - val_acc: 0.7433\n",
      "Epoch 141/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.6314 - acc: 0.7804 - val_loss: 0.5800 - val_acc: 0.8033\n",
      "Epoch 142/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5973 - acc: 0.7911 - val_loss: 0.5730 - val_acc: 0.8000\n",
      "Epoch 143/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5707 - acc: 0.8019 - val_loss: 0.5922 - val_acc: 0.7967\n",
      "Epoch 144/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5546 - acc: 0.8126 - val_loss: 0.5830 - val_acc: 0.8033\n",
      "Epoch 145/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5432 - acc: 0.8167 - val_loss: 0.5631 - val_acc: 0.8200\n",
      "Epoch 146/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5456 - acc: 0.8096 - val_loss: 0.5392 - val_acc: 0.8200\n",
      "Epoch 147/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5430 - acc: 0.8130 - val_loss: 0.5373 - val_acc: 0.8267\n",
      "Epoch 148/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5401 - acc: 0.8148 - val_loss: 0.5495 - val_acc: 0.8167\n",
      "Epoch 149/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5258 - acc: 0.8230 - val_loss: 0.5549 - val_acc: 0.7967\n",
      "Epoch 150/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5217 - acc: 0.8215 - val_loss: 0.5370 - val_acc: 0.8200\n",
      "Epoch 151/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5182 - acc: 0.8181 - val_loss: 0.5906 - val_acc: 0.8000\n",
      "Epoch 152/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5191 - acc: 0.8204 - val_loss: 0.5658 - val_acc: 0.8033\n",
      "Epoch 153/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5303 - acc: 0.8167 - val_loss: 0.5535 - val_acc: 0.8067\n",
      "Epoch 154/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5238 - acc: 0.8196 - val_loss: 0.5915 - val_acc: 0.7800\n",
      "Epoch 155/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5685 - acc: 0.7863 - val_loss: 0.5694 - val_acc: 0.7967\n",
      "Epoch 156/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5290 - acc: 0.8163 - val_loss: 0.5805 - val_acc: 0.7933\n",
      "Epoch 157/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.5202 - acc: 0.8222 - val_loss: 0.5352 - val_acc: 0.8100\n",
      "Epoch 158/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5081 - acc: 0.8233 - val_loss: 0.5164 - val_acc: 0.8133\n",
      "Epoch 159/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5021 - acc: 0.8241 - val_loss: 0.5118 - val_acc: 0.8267\n",
      "Epoch 160/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4908 - acc: 0.8311 - val_loss: 0.5040 - val_acc: 0.8267\n",
      "Epoch 161/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4983 - acc: 0.8252 - val_loss: 0.5563 - val_acc: 0.8200\n",
      "Epoch 162/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5113 - acc: 0.8219 - val_loss: 0.5788 - val_acc: 0.8000\n",
      "Epoch 163/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.5182 - acc: 0.8159 - val_loss: 0.5485 - val_acc: 0.8133\n",
      "Epoch 164/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4883 - acc: 0.8300 - val_loss: 0.5343 - val_acc: 0.8233\n",
      "Epoch 165/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5043 - acc: 0.8226 - val_loss: 0.6285 - val_acc: 0.7800\n",
      "Epoch 166/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5025 - acc: 0.8204 - val_loss: 0.5179 - val_acc: 0.8133\n",
      "Epoch 167/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4859 - acc: 0.8319 - val_loss: 0.5177 - val_acc: 0.8233\n",
      "Epoch 168/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4803 - acc: 0.8281 - val_loss: 0.5201 - val_acc: 0.8233\n",
      "Epoch 169/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4718 - acc: 0.8374 - val_loss: 0.5260 - val_acc: 0.8267\n",
      "Epoch 170/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4744 - acc: 0.8289 - val_loss: 0.5310 - val_acc: 0.8167\n",
      "Epoch 171/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4780 - acc: 0.8307 - val_loss: 0.5130 - val_acc: 0.8233\n",
      "Epoch 172/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4659 - acc: 0.8381 - val_loss: 0.5208 - val_acc: 0.8167\n",
      "Epoch 173/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4626 - acc: 0.8400 - val_loss: 0.5231 - val_acc: 0.8200\n",
      "Epoch 174/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4676 - acc: 0.8337 - val_loss: 0.5148 - val_acc: 0.8233\n",
      "Epoch 175/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4773 - acc: 0.8296 - val_loss: 0.5148 - val_acc: 0.8200\n",
      "Epoch 176/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4648 - acc: 0.8385 - val_loss: 0.5619 - val_acc: 0.8000\n",
      "Epoch 177/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4637 - acc: 0.8341 - val_loss: 0.4927 - val_acc: 0.8200\n",
      "Epoch 178/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4525 - acc: 0.8415 - val_loss: 0.4899 - val_acc: 0.8333\n",
      "Epoch 179/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4463 - acc: 0.8441 - val_loss: 0.5003 - val_acc: 0.8300\n",
      "Epoch 180/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4447 - acc: 0.8426 - val_loss: 0.4915 - val_acc: 0.8267\n",
      "Epoch 181/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4955 - acc: 0.8248 - val_loss: 0.5229 - val_acc: 0.8033\n",
      "Epoch 182/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5372 - acc: 0.7989 - val_loss: 0.5163 - val_acc: 0.8267\n",
      "Epoch 183/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.4581 - acc: 0.8363 - val_loss: 0.4922 - val_acc: 0.8167\n",
      "Epoch 184/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4517 - acc: 0.8419 - val_loss: 0.4855 - val_acc: 0.8367\n",
      "Epoch 185/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4381 - acc: 0.8470 - val_loss: 0.4842 - val_acc: 0.8400\n",
      "Epoch 186/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4345 - acc: 0.8456 - val_loss: 0.4789 - val_acc: 0.8367\n",
      "Epoch 187/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4315 - acc: 0.8456 - val_loss: 0.5023 - val_acc: 0.8167\n",
      "Epoch 188/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4335 - acc: 0.8481 - val_loss: 0.4975 - val_acc: 0.8200\n",
      "Epoch 189/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4331 - acc: 0.8444 - val_loss: 0.5344 - val_acc: 0.8067\n",
      "Epoch 190/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4381 - acc: 0.8381 - val_loss: 0.4810 - val_acc: 0.8333\n",
      "Epoch 191/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4454 - acc: 0.8344 - val_loss: 0.4815 - val_acc: 0.8300\n",
      "Epoch 192/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4368 - acc: 0.8426 - val_loss: 0.5106 - val_acc: 0.8200\n",
      "Epoch 193/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4372 - acc: 0.8452 - val_loss: 0.4708 - val_acc: 0.8267\n",
      "Epoch 194/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4457 - acc: 0.8407 - val_loss: 0.4965 - val_acc: 0.8200\n",
      "Epoch 195/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4530 - acc: 0.8363 - val_loss: 0.5256 - val_acc: 0.7933\n",
      "Epoch 196/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4405 - acc: 0.8481 - val_loss: 0.4567 - val_acc: 0.8400\n",
      "Epoch 197/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4344 - acc: 0.8437 - val_loss: 0.4360 - val_acc: 0.8433\n",
      "Epoch 198/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.4186 - acc: 0.8533 - val_loss: 0.4398 - val_acc: 0.8400\n",
      "Epoch 199/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4184 - acc: 0.8541 - val_loss: 0.4238 - val_acc: 0.8400\n",
      "Epoch 200/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4072 - acc: 0.8574 - val_loss: 0.4609 - val_acc: 0.8233\n",
      "Epoch 201/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4381 - acc: 0.8478 - val_loss: 0.4653 - val_acc: 0.8333\n",
      "Epoch 202/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4249 - acc: 0.8496 - val_loss: 0.4977 - val_acc: 0.8167\n",
      "Epoch 203/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4218 - acc: 0.8441 - val_loss: 0.4447 - val_acc: 0.8500\n",
      "Epoch 204/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.4016 - acc: 0.8596 - val_loss: 0.4485 - val_acc: 0.8367\n",
      "Epoch 205/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.4007 - acc: 0.8574 - val_loss: 0.4375 - val_acc: 0.8400\n",
      "Epoch 206/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3959 - acc: 0.8604 - val_loss: 0.4470 - val_acc: 0.8433\n",
      "Epoch 207/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3944 - acc: 0.8641 - val_loss: 0.4393 - val_acc: 0.8400\n",
      "Epoch 208/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3922 - acc: 0.8585 - val_loss: 0.4281 - val_acc: 0.8433\n",
      "Epoch 209/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3865 - acc: 0.8633 - val_loss: 0.4485 - val_acc: 0.8433\n",
      "Epoch 210/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3898 - acc: 0.8604 - val_loss: 0.4420 - val_acc: 0.8500\n",
      "Epoch 211/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3864 - acc: 0.8674 - val_loss: 0.4322 - val_acc: 0.8400\n",
      "Epoch 212/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3908 - acc: 0.8619 - val_loss: 0.4361 - val_acc: 0.8367\n",
      "Epoch 213/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.4000 - acc: 0.8574 - val_loss: 0.5207 - val_acc: 0.8133\n",
      "Epoch 214/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.4277 - acc: 0.8504 - val_loss: 0.4669 - val_acc: 0.8433\n",
      "Epoch 215/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3888 - acc: 0.8633 - val_loss: 0.4361 - val_acc: 0.8467\n",
      "Epoch 216/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3792 - acc: 0.8659 - val_loss: 0.4047 - val_acc: 0.8567\n",
      "Epoch 217/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3726 - acc: 0.8726 - val_loss: 0.3970 - val_acc: 0.8600\n",
      "Epoch 218/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3685 - acc: 0.8763 - val_loss: 0.3977 - val_acc: 0.8633\n",
      "Epoch 219/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3706 - acc: 0.8752 - val_loss: 0.3958 - val_acc: 0.8633\n",
      "Epoch 220/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3673 - acc: 0.8719 - val_loss: 0.4059 - val_acc: 0.8567\n",
      "Epoch 221/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3632 - acc: 0.8793 - val_loss: 0.4102 - val_acc: 0.8500\n",
      "Epoch 222/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3601 - acc: 0.8756 - val_loss: 0.4100 - val_acc: 0.8533\n",
      "Epoch 223/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3621 - acc: 0.8741 - val_loss: 0.4137 - val_acc: 0.8500\n",
      "Epoch 224/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3516 - acc: 0.8770 - val_loss: 0.4043 - val_acc: 0.8567\n",
      "Epoch 225/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3466 - acc: 0.8807 - val_loss: 0.4102 - val_acc: 0.8533\n",
      "Epoch 226/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3427 - acc: 0.8837 - val_loss: 0.3875 - val_acc: 0.8633\n",
      "Epoch 227/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3448 - acc: 0.8856 - val_loss: 0.4134 - val_acc: 0.8533\n",
      "Epoch 228/500\n",
      "2700/2700 [==============================] - 26s 9ms/step - loss: 0.3470 - acc: 0.8852 - val_loss: 0.4064 - val_acc: 0.8567\n",
      "Epoch 229/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3430 - acc: 0.8863 - val_loss: 0.4044 - val_acc: 0.8600\n",
      "Epoch 230/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3451 - acc: 0.8885 - val_loss: 0.4017 - val_acc: 0.8500\n",
      "Epoch 231/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.3429 - acc: 0.8889 - val_loss: 0.4056 - val_acc: 0.8533\n",
      "Epoch 232/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3371 - acc: 0.8889 - val_loss: 0.4062 - val_acc: 0.8567\n",
      "Epoch 233/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3333 - acc: 0.8841 - val_loss: 0.3823 - val_acc: 0.8667\n",
      "Epoch 234/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3276 - acc: 0.8907 - val_loss: 0.3910 - val_acc: 0.8667\n",
      "Epoch 235/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3274 - acc: 0.8881 - val_loss: 0.3865 - val_acc: 0.8500\n",
      "Epoch 236/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.5372 - acc: 0.8130 - val_loss: 0.5044 - val_acc: 0.8033\n",
      "Epoch 237/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3645 - acc: 0.8767 - val_loss: 0.3981 - val_acc: 0.8467\n",
      "Epoch 238/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3442 - acc: 0.8822 - val_loss: 0.4412 - val_acc: 0.8400\n",
      "Epoch 239/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3515 - acc: 0.8800 - val_loss: 0.4124 - val_acc: 0.8600\n",
      "Epoch 240/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3289 - acc: 0.8889 - val_loss: 0.3819 - val_acc: 0.8667\n",
      "Epoch 241/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3245 - acc: 0.8919 - val_loss: 0.3851 - val_acc: 0.8733\n",
      "Epoch 242/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3231 - acc: 0.8959 - val_loss: 0.3801 - val_acc: 0.8667\n",
      "Epoch 243/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3141 - acc: 0.8970 - val_loss: 0.3626 - val_acc: 0.8700\n",
      "Epoch 244/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3118 - acc: 0.8989 - val_loss: 0.3514 - val_acc: 0.8767\n",
      "Epoch 245/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3151 - acc: 0.8944 - val_loss: 0.3536 - val_acc: 0.8733\n",
      "Epoch 246/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3026 - acc: 0.9052 - val_loss: 0.3566 - val_acc: 0.8733\n",
      "Epoch 247/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3004 - acc: 0.8970 - val_loss: 0.3619 - val_acc: 0.8700\n",
      "Epoch 248/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3039 - acc: 0.9026 - val_loss: 0.3793 - val_acc: 0.8733\n",
      "Epoch 249/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3089 - acc: 0.8967 - val_loss: 0.3493 - val_acc: 0.8767\n",
      "Epoch 250/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.3010 - acc: 0.9044 - val_loss: 0.3921 - val_acc: 0.8633\n",
      "Epoch 251/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3007 - acc: 0.8970 - val_loss: 0.3698 - val_acc: 0.8800\n",
      "Epoch 252/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3132 - acc: 0.8989 - val_loss: 0.3575 - val_acc: 0.8867\n",
      "Epoch 253/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2850 - acc: 0.9107 - val_loss: 0.3446 - val_acc: 0.8733\n",
      "Epoch 254/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2937 - acc: 0.9096 - val_loss: 0.3554 - val_acc: 0.8800\n",
      "Epoch 255/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2905 - acc: 0.9041 - val_loss: 0.3434 - val_acc: 0.8867\n",
      "Epoch 256/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2961 - acc: 0.9037 - val_loss: 0.3456 - val_acc: 0.8867\n",
      "Epoch 257/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2923 - acc: 0.9033 - val_loss: 0.3618 - val_acc: 0.8833\n",
      "Epoch 258/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2919 - acc: 0.9056 - val_loss: 0.3566 - val_acc: 0.8633\n",
      "Epoch 259/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2821 - acc: 0.9111 - val_loss: 0.3699 - val_acc: 0.8833\n",
      "Epoch 260/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2725 - acc: 0.9144 - val_loss: 0.3405 - val_acc: 0.8800\n",
      "Epoch 261/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2736 - acc: 0.9174 - val_loss: 0.3560 - val_acc: 0.8867\n",
      "Epoch 262/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2686 - acc: 0.9141 - val_loss: 0.3529 - val_acc: 0.8833\n",
      "Epoch 263/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2694 - acc: 0.9152 - val_loss: 0.3404 - val_acc: 0.8800\n",
      "Epoch 264/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2777 - acc: 0.9093 - val_loss: 0.3453 - val_acc: 0.8867\n",
      "Epoch 265/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2716 - acc: 0.9156 - val_loss: 0.3228 - val_acc: 0.8900\n",
      "Epoch 266/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2650 - acc: 0.9211 - val_loss: 0.3434 - val_acc: 0.8800\n",
      "Epoch 267/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2609 - acc: 0.9185 - val_loss: 0.3386 - val_acc: 0.8833\n",
      "Epoch 268/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2612 - acc: 0.9207 - val_loss: 0.3421 - val_acc: 0.8933\n",
      "Epoch 269/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.2625 - acc: 0.9193 - val_loss: 0.3427 - val_acc: 0.8733\n",
      "Epoch 270/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2855 - acc: 0.9000 - val_loss: 0.3744 - val_acc: 0.8733\n",
      "Epoch 271/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2912 - acc: 0.9019 - val_loss: 0.3740 - val_acc: 0.8733\n",
      "Epoch 272/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2635 - acc: 0.9170 - val_loss: 0.3488 - val_acc: 0.8833\n",
      "Epoch 273/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2629 - acc: 0.9185 - val_loss: 0.3340 - val_acc: 0.8767\n",
      "Epoch 274/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2721 - acc: 0.9159 - val_loss: 0.3478 - val_acc: 0.8867\n",
      "Epoch 275/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2788 - acc: 0.9167 - val_loss: 0.4010 - val_acc: 0.8733\n",
      "Epoch 276/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2700 - acc: 0.9148 - val_loss: 0.3486 - val_acc: 0.8867\n",
      "Epoch 277/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2560 - acc: 0.9200 - val_loss: 0.3326 - val_acc: 0.9033\n",
      "Epoch 278/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2498 - acc: 0.9241 - val_loss: 0.3570 - val_acc: 0.8700\n",
      "Epoch 279/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.2733 - acc: 0.9096 - val_loss: 0.3270 - val_acc: 0.8967\n",
      "Epoch 280/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2516 - acc: 0.9204 - val_loss: 0.3271 - val_acc: 0.8900\n",
      "Epoch 281/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2390 - acc: 0.9281 - val_loss: 0.3243 - val_acc: 0.8967\n",
      "Epoch 282/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2498 - acc: 0.9237 - val_loss: 0.3360 - val_acc: 0.8967\n",
      "Epoch 283/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2650 - acc: 0.9181 - val_loss: 0.3467 - val_acc: 0.8800\n",
      "Epoch 284/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2453 - acc: 0.9319 - val_loss: 0.3175 - val_acc: 0.8900\n",
      "Epoch 285/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2386 - acc: 0.9289 - val_loss: 0.3279 - val_acc: 0.8967\n",
      "Epoch 286/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2371 - acc: 0.9315 - val_loss: 0.3374 - val_acc: 0.8900\n",
      "Epoch 287/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2368 - acc: 0.9293 - val_loss: 0.3382 - val_acc: 0.8967\n",
      "Epoch 288/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2320 - acc: 0.9311 - val_loss: 0.3250 - val_acc: 0.8867\n",
      "Epoch 289/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2226 - acc: 0.9407 - val_loss: 0.3061 - val_acc: 0.8967\n",
      "Epoch 290/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2182 - acc: 0.9359 - val_loss: 0.3203 - val_acc: 0.8900\n",
      "Epoch 291/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2184 - acc: 0.9404 - val_loss: 0.3082 - val_acc: 0.9033\n",
      "Epoch 292/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2134 - acc: 0.9430 - val_loss: 0.3326 - val_acc: 0.9033\n",
      "Epoch 293/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2091 - acc: 0.9441 - val_loss: 0.3045 - val_acc: 0.9133\n",
      "Epoch 294/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2144 - acc: 0.9426 - val_loss: 0.3151 - val_acc: 0.9033\n",
      "Epoch 295/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2211 - acc: 0.9374 - val_loss: 0.3212 - val_acc: 0.9000\n",
      "Epoch 296/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.4403 - acc: 0.8659 - val_loss: 0.6094 - val_acc: 0.8133\n",
      "Epoch 297/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.3586 - acc: 0.8737 - val_loss: 0.3301 - val_acc: 0.8967\n",
      "Epoch 298/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2338 - acc: 0.9304 - val_loss: 0.3080 - val_acc: 0.9100\n",
      "Epoch 299/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2342 - acc: 0.9344 - val_loss: 0.3076 - val_acc: 0.9133\n",
      "Epoch 300/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2143 - acc: 0.9396 - val_loss: 0.3053 - val_acc: 0.9100\n",
      "Epoch 301/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2186 - acc: 0.9426 - val_loss: 0.3278 - val_acc: 0.9033\n",
      "Epoch 302/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2028 - acc: 0.9467 - val_loss: 0.2968 - val_acc: 0.9167\n",
      "Epoch 303/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2027 - acc: 0.9485 - val_loss: 0.3002 - val_acc: 0.9200\n",
      "Epoch 304/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2263 - acc: 0.9385 - val_loss: 0.3477 - val_acc: 0.8867\n",
      "Epoch 305/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2390 - acc: 0.9293 - val_loss: 0.3170 - val_acc: 0.8967\n",
      "Epoch 306/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.2093 - acc: 0.9419 - val_loss: 0.3315 - val_acc: 0.8967\n",
      "Epoch 307/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1951 - acc: 0.9485 - val_loss: 0.3057 - val_acc: 0.9167\n",
      "Epoch 308/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1978 - acc: 0.9474 - val_loss: 0.3172 - val_acc: 0.9033\n",
      "Epoch 309/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1906 - acc: 0.9511 - val_loss: 0.2914 - val_acc: 0.9167\n",
      "Epoch 310/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1839 - acc: 0.9552 - val_loss: 0.3002 - val_acc: 0.9133\n",
      "Epoch 311/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1889 - acc: 0.9481 - val_loss: 0.2846 - val_acc: 0.9167\n",
      "Epoch 312/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1899 - acc: 0.9463 - val_loss: 0.2906 - val_acc: 0.9200\n",
      "Epoch 313/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1847 - acc: 0.9470 - val_loss: 0.2706 - val_acc: 0.9200\n",
      "Epoch 314/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1873 - acc: 0.9456 - val_loss: 0.2905 - val_acc: 0.9167\n",
      "Epoch 315/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1756 - acc: 0.9567 - val_loss: 0.3115 - val_acc: 0.9100\n",
      "Epoch 316/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.2101 - acc: 0.9404 - val_loss: 0.3150 - val_acc: 0.9000\n",
      "Epoch 317/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1881 - acc: 0.9478 - val_loss: 0.2873 - val_acc: 0.9200\n",
      "Epoch 318/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1727 - acc: 0.9515 - val_loss: 0.2811 - val_acc: 0.9233\n",
      "Epoch 319/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1741 - acc: 0.9500 - val_loss: 0.2953 - val_acc: 0.9100\n",
      "Epoch 320/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1671 - acc: 0.9552 - val_loss: 0.2714 - val_acc: 0.9233\n",
      "Epoch 321/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1703 - acc: 0.9515 - val_loss: 0.2977 - val_acc: 0.9133\n",
      "Epoch 322/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1790 - acc: 0.9522 - val_loss: 0.2733 - val_acc: 0.9167\n",
      "Epoch 323/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1691 - acc: 0.9567 - val_loss: 0.2811 - val_acc: 0.9133\n",
      "Epoch 324/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1683 - acc: 0.9526 - val_loss: 0.2598 - val_acc: 0.9233\n",
      "Epoch 325/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1795 - acc: 0.9489 - val_loss: 0.3107 - val_acc: 0.9033\n",
      "Epoch 326/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1892 - acc: 0.9422 - val_loss: 0.2757 - val_acc: 0.9167\n",
      "Epoch 327/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1654 - acc: 0.9559 - val_loss: 0.2695 - val_acc: 0.9167\n",
      "Epoch 328/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1724 - acc: 0.9463 - val_loss: 0.2789 - val_acc: 0.9067\n",
      "Epoch 329/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1633 - acc: 0.9511 - val_loss: 0.2650 - val_acc: 0.9233\n",
      "Epoch 330/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1596 - acc: 0.9567 - val_loss: 0.2673 - val_acc: 0.9200\n",
      "Epoch 331/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1517 - acc: 0.9607 - val_loss: 0.2601 - val_acc: 0.9200\n",
      "Epoch 332/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1486 - acc: 0.9593 - val_loss: 0.2612 - val_acc: 0.9200\n",
      "Epoch 333/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1583 - acc: 0.9559 - val_loss: 0.2762 - val_acc: 0.9200\n",
      "Epoch 334/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1672 - acc: 0.9470 - val_loss: 0.2658 - val_acc: 0.9167\n",
      "Epoch 335/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1590 - acc: 0.9533 - val_loss: 0.2651 - val_acc: 0.9100\n",
      "Epoch 336/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1482 - acc: 0.9578 - val_loss: 0.2949 - val_acc: 0.9100\n",
      "Epoch 337/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1522 - acc: 0.9578 - val_loss: 0.2690 - val_acc: 0.9167\n",
      "Epoch 338/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1695 - acc: 0.9493 - val_loss: 0.2428 - val_acc: 0.9267\n",
      "Epoch 339/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1503 - acc: 0.9589 - val_loss: 0.2243 - val_acc: 0.9400\n",
      "Epoch 340/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1457 - acc: 0.9600 - val_loss: 0.2693 - val_acc: 0.9100\n",
      "Epoch 341/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1521 - acc: 0.9574 - val_loss: 0.2695 - val_acc: 0.9233\n",
      "Epoch 342/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1484 - acc: 0.9559 - val_loss: 0.2581 - val_acc: 0.9200\n",
      "Epoch 343/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1424 - acc: 0.9604 - val_loss: 0.2339 - val_acc: 0.9233\n",
      "Epoch 344/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1423 - acc: 0.9604 - val_loss: 0.2232 - val_acc: 0.9300\n",
      "Epoch 345/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1557 - acc: 0.9544 - val_loss: 0.2264 - val_acc: 0.9233\n",
      "Epoch 346/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1659 - acc: 0.9459 - val_loss: 0.2606 - val_acc: 0.9167\n",
      "Epoch 347/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1481 - acc: 0.9567 - val_loss: 0.2101 - val_acc: 0.9233\n",
      "Epoch 348/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1359 - acc: 0.9619 - val_loss: 0.2673 - val_acc: 0.9133\n",
      "Epoch 349/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1457 - acc: 0.9552 - val_loss: 0.2186 - val_acc: 0.9467\n",
      "Epoch 350/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1462 - acc: 0.9574 - val_loss: 0.2647 - val_acc: 0.9067\n",
      "Epoch 351/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1423 - acc: 0.9574 - val_loss: 0.2113 - val_acc: 0.9400\n",
      "Epoch 352/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1297 - acc: 0.9630 - val_loss: 0.2235 - val_acc: 0.9267\n",
      "Epoch 353/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1313 - acc: 0.9619 - val_loss: 0.2282 - val_acc: 0.9233\n",
      "Epoch 354/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1326 - acc: 0.9607 - val_loss: 0.2090 - val_acc: 0.9300\n",
      "Epoch 355/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1364 - acc: 0.9619 - val_loss: 0.2782 - val_acc: 0.9233\n",
      "Epoch 356/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1480 - acc: 0.9522 - val_loss: 0.1965 - val_acc: 0.9333\n",
      "Epoch 357/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1360 - acc: 0.9626 - val_loss: 0.1812 - val_acc: 0.9433\n",
      "Epoch 358/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1318 - acc: 0.9615 - val_loss: 0.1826 - val_acc: 0.9333\n",
      "Epoch 359/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1258 - acc: 0.9648 - val_loss: 0.1809 - val_acc: 0.9433\n",
      "Epoch 360/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1305 - acc: 0.9615 - val_loss: 0.2049 - val_acc: 0.9267\n",
      "Epoch 361/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1329 - acc: 0.9607 - val_loss: 0.1856 - val_acc: 0.9333\n",
      "Epoch 362/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1261 - acc: 0.9644 - val_loss: 0.1970 - val_acc: 0.9400\n",
      "Epoch 363/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1207 - acc: 0.9648 - val_loss: 0.1942 - val_acc: 0.9433\n",
      "Epoch 364/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1183 - acc: 0.9681 - val_loss: 0.1820 - val_acc: 0.9467\n",
      "Epoch 365/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1243 - acc: 0.9626 - val_loss: 0.1698 - val_acc: 0.9400\n",
      "Epoch 366/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1247 - acc: 0.9626 - val_loss: 0.2078 - val_acc: 0.9167\n",
      "Epoch 367/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.1516 - acc: 0.9526 - val_loss: 0.1886 - val_acc: 0.9333\n",
      "Epoch 368/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1242 - acc: 0.9652 - val_loss: 0.2037 - val_acc: 0.9367\n",
      "Epoch 369/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1188 - acc: 0.9644 - val_loss: 0.1863 - val_acc: 0.9400\n",
      "Epoch 370/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1118 - acc: 0.9722 - val_loss: 0.1771 - val_acc: 0.9500\n",
      "Epoch 371/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1192 - acc: 0.9652 - val_loss: 0.1699 - val_acc: 0.9467\n",
      "Epoch 372/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1141 - acc: 0.9663 - val_loss: 0.1921 - val_acc: 0.9400\n",
      "Epoch 373/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1172 - acc: 0.9659 - val_loss: 0.1796 - val_acc: 0.9333\n",
      "Epoch 374/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1721 - acc: 0.9415 - val_loss: 0.2577 - val_acc: 0.9133\n",
      "Epoch 375/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1151 - acc: 0.9663 - val_loss: 0.1753 - val_acc: 0.9433\n",
      "Epoch 376/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1099 - acc: 0.9685 - val_loss: 0.1721 - val_acc: 0.9467\n",
      "Epoch 377/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1154 - acc: 0.9674 - val_loss: 0.1449 - val_acc: 0.9500\n",
      "Epoch 378/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1083 - acc: 0.9711 - val_loss: 0.1463 - val_acc: 0.9467\n",
      "Epoch 379/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1092 - acc: 0.9689 - val_loss: 0.1544 - val_acc: 0.9467\n",
      "Epoch 380/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1310 - acc: 0.9630 - val_loss: 0.1946 - val_acc: 0.9400\n",
      "Epoch 381/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1091 - acc: 0.9693 - val_loss: 0.1418 - val_acc: 0.9467\n",
      "Epoch 382/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1071 - acc: 0.9696 - val_loss: 0.1422 - val_acc: 0.9633\n",
      "Epoch 383/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1319 - acc: 0.9630 - val_loss: 0.5462 - val_acc: 0.8367\n",
      "Epoch 384/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2415 - acc: 0.9330 - val_loss: 0.2224 - val_acc: 0.9400\n",
      "Epoch 385/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1308 - acc: 0.9648 - val_loss: 0.1877 - val_acc: 0.9400\n",
      "Epoch 386/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1147 - acc: 0.9700 - val_loss: 0.1857 - val_acc: 0.9433\n",
      "Epoch 387/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1253 - acc: 0.9615 - val_loss: 0.1586 - val_acc: 0.9533\n",
      "Epoch 388/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1226 - acc: 0.9674 - val_loss: 0.1690 - val_acc: 0.9400\n",
      "Epoch 389/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1260 - acc: 0.9619 - val_loss: 0.1787 - val_acc: 0.9333\n",
      "Epoch 390/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1311 - acc: 0.9619 - val_loss: 0.1806 - val_acc: 0.9333\n",
      "Epoch 391/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1050 - acc: 0.9715 - val_loss: 0.1707 - val_acc: 0.9300\n",
      "Epoch 392/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1089 - acc: 0.9685 - val_loss: 0.1620 - val_acc: 0.9433\n",
      "Epoch 393/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1006 - acc: 0.9707 - val_loss: 0.1519 - val_acc: 0.9467\n",
      "Epoch 394/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0946 - acc: 0.9741 - val_loss: 0.1635 - val_acc: 0.9433\n",
      "Epoch 395/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0953 - acc: 0.9730 - val_loss: 0.1453 - val_acc: 0.9567\n",
      "Epoch 396/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1016 - acc: 0.9707 - val_loss: 0.1701 - val_acc: 0.9333\n",
      "Epoch 397/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0973 - acc: 0.9741 - val_loss: 0.1491 - val_acc: 0.9467\n",
      "Epoch 398/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1012 - acc: 0.9711 - val_loss: 0.1370 - val_acc: 0.9633\n",
      "Epoch 399/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0910 - acc: 0.9763 - val_loss: 0.1372 - val_acc: 0.9533\n",
      "Epoch 400/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0918 - acc: 0.9744 - val_loss: 0.1441 - val_acc: 0.9567\n",
      "Epoch 401/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0994 - acc: 0.9722 - val_loss: 0.1313 - val_acc: 0.9600\n",
      "Epoch 402/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0866 - acc: 0.9763 - val_loss: 0.1499 - val_acc: 0.9433\n",
      "Epoch 403/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0872 - acc: 0.9744 - val_loss: 0.1590 - val_acc: 0.9467\n",
      "Epoch 404/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0877 - acc: 0.9774 - val_loss: 0.1447 - val_acc: 0.9567\n",
      "Epoch 405/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0912 - acc: 0.9741 - val_loss: 0.1382 - val_acc: 0.9533\n",
      "Epoch 406/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1027 - acc: 0.9696 - val_loss: 0.1261 - val_acc: 0.9467\n",
      "Epoch 407/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0934 - acc: 0.9774 - val_loss: 0.1353 - val_acc: 0.9567\n",
      "Epoch 408/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0928 - acc: 0.9722 - val_loss: 0.1359 - val_acc: 0.9533\n",
      "Epoch 409/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0916 - acc: 0.9778 - val_loss: 0.1461 - val_acc: 0.9500\n",
      "Epoch 410/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1114 - acc: 0.9685 - val_loss: 0.1450 - val_acc: 0.9500\n",
      "Epoch 411/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1012 - acc: 0.9719 - val_loss: 0.2228 - val_acc: 0.9433\n",
      "Epoch 412/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0934 - acc: 0.9767 - val_loss: 0.1974 - val_acc: 0.9400\n",
      "Epoch 413/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1000 - acc: 0.9715 - val_loss: 0.1781 - val_acc: 0.9533\n",
      "Epoch 414/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0942 - acc: 0.9730 - val_loss: 0.1630 - val_acc: 0.9467\n",
      "Epoch 415/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0916 - acc: 0.9741 - val_loss: 0.1884 - val_acc: 0.9433\n",
      "Epoch 416/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0767 - acc: 0.9793 - val_loss: 0.1252 - val_acc: 0.9700\n",
      "Epoch 417/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1766 - acc: 0.9604 - val_loss: 0.6452 - val_acc: 0.8633\n",
      "Epoch 418/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2138 - acc: 0.9444 - val_loss: 0.1850 - val_acc: 0.9400\n",
      "Epoch 419/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1141 - acc: 0.9689 - val_loss: 0.2238 - val_acc: 0.9167\n",
      "Epoch 420/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1518 - acc: 0.9522 - val_loss: 0.1586 - val_acc: 0.9500\n",
      "Epoch 421/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0900 - acc: 0.9759 - val_loss: 0.1659 - val_acc: 0.9467\n",
      "Epoch 422/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0826 - acc: 0.9804 - val_loss: 0.1687 - val_acc: 0.9533\n",
      "Epoch 423/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0845 - acc: 0.9770 - val_loss: 0.1835 - val_acc: 0.9333\n",
      "Epoch 424/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1148 - acc: 0.9670 - val_loss: 0.1513 - val_acc: 0.9500\n",
      "Epoch 425/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1240 - acc: 0.9581 - val_loss: 0.1736 - val_acc: 0.9267\n",
      "Epoch 426/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0992 - acc: 0.9693 - val_loss: 0.1421 - val_acc: 0.9600\n",
      "Epoch 427/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0786 - acc: 0.9796 - val_loss: 0.1452 - val_acc: 0.9667\n",
      "Epoch 428/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0910 - acc: 0.9763 - val_loss: 0.1677 - val_acc: 0.9600\n",
      "Epoch 429/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0758 - acc: 0.9804 - val_loss: 0.1311 - val_acc: 0.9567\n",
      "Epoch 430/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0875 - acc: 0.9770 - val_loss: 0.1493 - val_acc: 0.9467\n",
      "Epoch 431/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0779 - acc: 0.9811 - val_loss: 0.1511 - val_acc: 0.9600\n",
      "Epoch 432/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0745 - acc: 0.9804 - val_loss: 0.1497 - val_acc: 0.9600\n",
      "Epoch 433/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1398 - acc: 0.9526 - val_loss: 0.3123 - val_acc: 0.9067\n",
      "Epoch 434/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1173 - acc: 0.9674 - val_loss: 0.1583 - val_acc: 0.9567\n",
      "Epoch 435/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0846 - acc: 0.9770 - val_loss: 0.1323 - val_acc: 0.9633\n",
      "Epoch 436/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0939 - acc: 0.9733 - val_loss: 0.1366 - val_acc: 0.9500\n",
      "Epoch 437/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0883 - acc: 0.9781 - val_loss: 0.1529 - val_acc: 0.9500\n",
      "Epoch 438/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0876 - acc: 0.9741 - val_loss: 0.1437 - val_acc: 0.9567\n",
      "Epoch 439/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0753 - acc: 0.9819 - val_loss: 0.1468 - val_acc: 0.9567\n",
      "Epoch 440/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0900 - acc: 0.9748 - val_loss: 0.1582 - val_acc: 0.9467\n",
      "Epoch 441/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0808 - acc: 0.9789 - val_loss: 0.1390 - val_acc: 0.9500\n",
      "Epoch 442/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0823 - acc: 0.9733 - val_loss: 0.1395 - val_acc: 0.9567\n",
      "Epoch 443/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0654 - acc: 0.9837 - val_loss: 0.1336 - val_acc: 0.9633\n",
      "Epoch 444/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0712 - acc: 0.9804 - val_loss: 0.1386 - val_acc: 0.9667\n",
      "Epoch 445/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0724 - acc: 0.9826 - val_loss: 0.1168 - val_acc: 0.9733\n",
      "Epoch 446/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0744 - acc: 0.9778 - val_loss: 0.1414 - val_acc: 0.9500\n",
      "Epoch 447/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0660 - acc: 0.9822 - val_loss: 0.1521 - val_acc: 0.9533\n",
      "Epoch 448/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0666 - acc: 0.9822 - val_loss: 0.1388 - val_acc: 0.9533\n",
      "Epoch 449/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0667 - acc: 0.9837 - val_loss: 0.1334 - val_acc: 0.9667\n",
      "Epoch 450/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0680 - acc: 0.9800 - val_loss: 0.1449 - val_acc: 0.9567\n",
      "Epoch 451/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0664 - acc: 0.9833 - val_loss: 0.1304 - val_acc: 0.9633\n",
      "Epoch 452/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0623 - acc: 0.9830 - val_loss: 0.1382 - val_acc: 0.9533\n",
      "Epoch 453/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0900 - acc: 0.9767 - val_loss: 0.1917 - val_acc: 0.9367\n",
      "Epoch 454/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0697 - acc: 0.9811 - val_loss: 0.1231 - val_acc: 0.9567\n",
      "Epoch 455/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0714 - acc: 0.9793 - val_loss: 0.1156 - val_acc: 0.9633\n",
      "Epoch 456/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0638 - acc: 0.9830 - val_loss: 0.1314 - val_acc: 0.9600\n",
      "Epoch 457/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0784 - acc: 0.9778 - val_loss: 0.1230 - val_acc: 0.9500\n",
      "Epoch 458/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1345 - acc: 0.9585 - val_loss: 0.2989 - val_acc: 0.9233\n",
      "Epoch 459/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1070 - acc: 0.9693 - val_loss: 0.1305 - val_acc: 0.9633\n",
      "Epoch 460/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0793 - acc: 0.9767 - val_loss: 0.1293 - val_acc: 0.9700\n",
      "Epoch 461/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0820 - acc: 0.9789 - val_loss: 0.1613 - val_acc: 0.9533\n",
      "Epoch 462/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0818 - acc: 0.9748 - val_loss: 0.1232 - val_acc: 0.9600\n",
      "Epoch 463/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0700 - acc: 0.9778 - val_loss: 0.1248 - val_acc: 0.9667\n",
      "Epoch 464/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0611 - acc: 0.9844 - val_loss: 0.1240 - val_acc: 0.9533\n",
      "Epoch 465/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0657 - acc: 0.9815 - val_loss: 0.1298 - val_acc: 0.9533\n",
      "Epoch 466/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0714 - acc: 0.9807 - val_loss: 0.1579 - val_acc: 0.9533\n",
      "Epoch 467/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0725 - acc: 0.9793 - val_loss: 0.1471 - val_acc: 0.9667\n",
      "Epoch 468/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0698 - acc: 0.9807 - val_loss: 0.1161 - val_acc: 0.9667\n",
      "Epoch 469/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0555 - acc: 0.9881 - val_loss: 0.1039 - val_acc: 0.9633\n",
      "Epoch 470/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0586 - acc: 0.9833 - val_loss: 0.1223 - val_acc: 0.9667\n",
      "Epoch 471/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0572 - acc: 0.9859 - val_loss: 0.1248 - val_acc: 0.9700\n",
      "Epoch 472/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0899 - acc: 0.9733 - val_loss: 0.1156 - val_acc: 0.9700\n",
      "Epoch 473/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2739 - acc: 0.9152 - val_loss: 0.4874 - val_acc: 0.8533\n",
      "Epoch 474/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.2822 - acc: 0.8930 - val_loss: 0.1735 - val_acc: 0.9433\n",
      "Epoch 475/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1420 - acc: 0.9611 - val_loss: 0.1544 - val_acc: 0.9633\n",
      "Epoch 476/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.1087 - acc: 0.9767 - val_loss: 0.1322 - val_acc: 0.9667\n",
      "Epoch 477/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0974 - acc: 0.9774 - val_loss: 0.1349 - val_acc: 0.9767\n",
      "Epoch 478/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0822 - acc: 0.9837 - val_loss: 0.1588 - val_acc: 0.9500\n",
      "Epoch 479/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0838 - acc: 0.9789 - val_loss: 0.1659 - val_acc: 0.9500\n",
      "Epoch 480/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0771 - acc: 0.9822 - val_loss: 0.1567 - val_acc: 0.9500\n",
      "Epoch 481/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0772 - acc: 0.9811 - val_loss: 0.1536 - val_acc: 0.9567\n",
      "Epoch 482/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0779 - acc: 0.9807 - val_loss: 0.1325 - val_acc: 0.9767\n",
      "Epoch 483/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0987 - acc: 0.9707 - val_loss: 0.3009 - val_acc: 0.9133\n",
      "Epoch 484/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.1834 - acc: 0.9489 - val_loss: 0.1210 - val_acc: 0.9700\n",
      "Epoch 485/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.1148 - acc: 0.9652 - val_loss: 0.1596 - val_acc: 0.9500\n",
      "Epoch 486/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0772 - acc: 0.9796 - val_loss: 0.1286 - val_acc: 0.9667\n",
      "Epoch 487/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0815 - acc: 0.9781 - val_loss: 0.1253 - val_acc: 0.9600\n",
      "Epoch 488/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0595 - acc: 0.9885 - val_loss: 0.1367 - val_acc: 0.9567\n",
      "Epoch 489/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0527 - acc: 0.9900 - val_loss: 0.1365 - val_acc: 0.9567\n",
      "Epoch 490/500\n",
      "2700/2700 [==============================] - 22s 8ms/step - loss: 0.0528 - acc: 0.9893 - val_loss: 0.1194 - val_acc: 0.9667\n",
      "Epoch 491/500\n",
      "2700/2700 [==============================] - 23s 8ms/step - loss: 0.0542 - acc: 0.9896 - val_loss: 0.1187 - val_acc: 0.9600\n",
      "Epoch 492/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0579 - acc: 0.9833 - val_loss: 0.1190 - val_acc: 0.9567\n",
      "Epoch 493/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0552 - acc: 0.9878 - val_loss: 0.1159 - val_acc: 0.9633\n",
      "Epoch 494/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0534 - acc: 0.9867 - val_loss: 0.1469 - val_acc: 0.9533\n",
      "Epoch 495/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.0551 - acc: 0.9874 - val_loss: 0.1745 - val_acc: 0.9567\n",
      "Epoch 496/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.0592 - acc: 0.9848 - val_loss: 0.1248 - val_acc: 0.9633\n",
      "Epoch 497/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0472 - acc: 0.9904 - val_loss: 0.1308 - val_acc: 0.9633\n",
      "Epoch 498/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0475 - acc: 0.9904 - val_loss: 0.1309 - val_acc: 0.9633\n",
      "Epoch 499/500\n",
      "2700/2700 [==============================] - 23s 9ms/step - loss: 0.0493 - acc: 0.9900 - val_loss: 0.1319 - val_acc: 0.9600\n",
      "Epoch 500/500\n",
      "2700/2700 [==============================] - 24s 9ms/step - loss: 0.0613 - acc: 0.9874 - val_loss: 0.2634 - val_acc: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25eadd551d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training ------------')\n",
    "model.fit(train_sets, train_label, epochs=500, batch_size=100, validation_data=(test_sets, test_label), shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
